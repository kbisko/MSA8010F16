{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Homework 1: Word Frequencies\n",
    "\n",
    "## Challenge\n",
    "Can we identify different types of text documents based on the frequency of their words? Can we identify different authors, styles, or disciplines like medical versus information technology? The assignment is to compute word frequencies for different types of documents, and to develop patterns for document classification.\n",
    "\n",
    "## Tasks\n",
    "1. Write Python code to load different text documents and compute word frequencies. The most frequent words should be at the beginning of the list.\n",
    "2. Identify a small (about 5 to 10) words that could represent a particular type of document.\n",
    "3. Show how different types have different word lists (\"signatures\").\n",
    "4. Discuss results and the feasibilty of this method.\n",
    "\n",
    "## Deliverable\n",
    "Use this notebook to implement your assignment. Please, observe the following:\n",
    "1. Your notebook should have the completly executed code and results.\n",
    "2. Please, organize your notebook to tell the story. Remove unnecessary clutter, test code, and anything that does not belong to the story.\n",
    "3. Save your notebook in a directory named `HW1` in `MSA8010F16` in your *home* directory on the Hadoop Cluster. The path should be `~/MSA8010F16/HW1/HW1.ipynb`.\n",
    "4. Also save the notebook in HTML as `~/MSA8010F16/HW1/HW1.html`\n",
    "5. All file names are *case sensitive*!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "##Step 1: Load the data\n",
    "from urllib.request import urlopen\n",
    "import string\n",
    "with urlopen('http://ocw.mit.edu/ans7870/6/6.006/s08/lecturenotes/files/t8.shakespeare.txt') as src:\n",
    "    words = []\n",
    "    txt = src.readlines()\n",
    "    for t in txt[244:]:\n",
    "        words = words + (t.decode().replace('\\n','').casefold().split(' '))    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 71,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "##Step 2: remove all the punctuation \n",
    "def remove_punct(doc):\n",
    "    import re\n",
    "    from string import punctuation\n",
    "    r = re.compile(r'[{}]'.format(punctuation))\n",
    "    output = []\n",
    "    for x in doc:\n",
    "        output.append(r.sub('',x))\n",
    "    return output\n",
    "\n",
    "words2 = remove_punct(words)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 72,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "##Step 3: Remove empty entries\n",
    "words3 = [w for w in words2 if w]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 73,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "##Step 4: remove stop words\n",
    "def remove_stops(doc):\n",
    "    with urlopen('http://www.textfixer.com/resources/common-english-words.txt') as stop_words_src:\n",
    "        stop_words = []\n",
    "        sw = stop_words_src.readlines()\n",
    "        for x in sw:\n",
    "            stop_words = stop_words + (x.decode().split(','))   \n",
    "    return [w for w in doc if w not in stop_words]\n",
    "\n",
    "words4 = remove_stops(words3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 92,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[('thou', 5485), ('thy', 4032), ('shall', 3591), ('thee', 3178), ('lord', 3059), ('king', 2861), ('good', 2812), ('now', 2778), ('sir', 2754), ('o', 2607), ('come', 2507), ('well', 2462), ('more', 2288), ('here', 2114), ('enter', 2098), ('love', 2053), ('ill', 1972), ('hath', 1941), ('man', 1835), ('one', 1779), ('go', 1733), ('upon', 1731), ('know', 1647), ('make', 1629), ('such', 1608)]\n"
     ]
    }
   ],
   "source": [
    "##Step 5: Find the top 20 meaningful words in the document\n",
    "def find_top25_words(doc):\n",
    "    from collections import Counter\n",
    "    freq = Counter(doc)\n",
    "    top25 = freq.most_common(25)    \n",
    "    return (top25)    \n",
    "\n",
    "print (find_top25_words(words4))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "Now with all of the necessary program developed these can be run quickly for other documents. \n",
    "First, lets see if other classical works from the Renaissance could be picked out using the above words.\n",
    "If we take out the thou, thy, thee, and shalls which really don't matter, we're left with:\n",
    "    lord\n",
    "    king\n",
    "    good\n",
    "    sir\n",
    "    come\n",
    "    well\n",
    "    more\n",
    "    here\n",
    "    enter\n",
    "    love\n",
    "    ill\n",
    "    man\n",
    "    one\n",
    "    go\n",
    "    know\n",
    "    make"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 93,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[('faustus', 292), ('thou', 119), ('mephist', 72), ('thee', 72), ('shall', 66), ('ill', 58), ('mephistophilis', 57), ('thy', 54), ('now', 51), ('come', 50), ('soul', 47), ('hell', 43), ('god', 43), ('lucifer', 42), ('o', 39), ('wagner', 37), ('see', 37), ('enter', 36), ('art', 35), ('tell', 33), ('good', 32), ('well', 30), ('sir', 28), ('doctor', 28), ('scholar', 27)]\n"
     ]
    }
   ],
   "source": [
    "##The Tragical History of Doctor Faustus by Christopher Marlowe\n",
    "from urllib.request import urlopen\n",
    "import string\n",
    "with urlopen('http://www.gutenberg.org/cache/epub/779/pg779.txt') as src:\n",
    "    marlowe = []\n",
    "    txt = src.readlines()\n",
    "    for t in txt[55:2147]:\n",
    "        marlowe = marlowe + (t.decode().replace('\\n','').replace('\\r','').casefold().split(' '))    \n",
    "\n",
    "marlowe2 = remove_punct(marlowe)\n",
    "marlowe3 = [w for w in marlowe2 if w]\n",
    "marlowe4 = remove_stops(marlowe3)\n",
    "marlowe5 = find_top25_words(marlowe4)\n",
    "print (marlowe5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "If we remove faustus, memphist, and mephistophilis as the character's name the remaining words are all very similar to the Shakespearean words.\n",
    "4 out of the first 5 are the same: thou, thee, shall, thy. \n",
    "These are all standard words, perphas they could help us determine the era and the remaining top words could help destinguish the authors? \n",
    "    ill\n",
    "    now\n",
    "    come\n",
    "    soul\n",
    "    hell\n",
    "    god\n",
    "    lucifer\n",
    "    see\n",
    "    enter\n",
    "    art\n",
    "    tell\n",
    "    good\n",
    "    well\n",
    "    sir\n",
    "    doctor\n",
    "    scholar\n",
    "Lets look at another work from the same period. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 94,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[('knight', 169), ('faire', 128), ('great', 127), ('now', 121), ('gan', 112), ('through', 101), ('well', 93), ('doth', 92), ('long', 89), ('forth', 89), ('whose', 86), ('unto', 84), ('way', 80), ('ne', 78), ('full', 74), ('life', 73), ('day', 72), ('up', 72), ('thy', 71), ('such', 71), ('never', 71), ('both', 69), ('man', 67), ('upon', 66), ('made', 66)]\n"
     ]
    }
   ],
   "source": [
    "##Spenser's The Faerie Queene\n",
    "from urllib.request import urlopen\n",
    "import string\n",
    "with urlopen('http://www.gutenberg.org/cache/epub/15272/pg15272.txt') as src:\n",
    "    spencer = []\n",
    "    txt = src.readlines()\n",
    "    for t in txt[994:8535]:\n",
    "        spencer = spencer + (t.decode().replace('\\n','').replace('\\r','').casefold().split(' '))    \n",
    "\n",
    "spencer2 = remove_punct(spencer)\n",
    "spencer3 = [w for w in spencer2 if w]\n",
    "spencer4 = remove_stops(spencer3)\n",
    "spencer5 = find_top25_words(spencer4)\n",
    "print (spencer5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "    knight\n",
    "    faire\n",
    "    great\n",
    "    now\n",
    "    gan\n",
    "    well\n",
    "    long\n",
    "    way\n",
    "    full\n",
    "    life\n",
    "    day\n",
    "    never\n",
    "    both\n",
    "    man\n",
    "    made\n",
    "This document doesn't seem to fit the initial word list from Shakespeare and Marlowe. \n",
    "The only word that is the same in all 3 is now...\n",
    "So we probably can't get as specific as era. \n",
    "Maybe distinguish between fiction authors? Lets try it with Jane Austen. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 108,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[('elinor', 618), ('mrs', 526), ('very', 497), ('marianne', 490), ('more', 407), ('such', 358), ('one', 327), ('much', 287), ('herself', 249), ('time', 241), ('now', 234), ('know', 229), ('dashwood', 224), ('sister', 214), ('though', 213), ('edward', 210), ('well', 209), ('miss', 209), ('think', 206), ('jennings', 203), ('mother', 199), ('before', 198), ('never', 186), ('thing', 184), ('nothing', 180)]\n"
     ]
    }
   ],
   "source": [
    "##Austen - Sense & Sensibility\n",
    "from urllib.request import urlopen\n",
    "import string\n",
    "with urlopen('http://www.textfiles.com/etext/FICTION/austen-sense-758.txt') as src:\n",
    "    sense = []\n",
    "    txt = src.readlines()\n",
    "    for t in txt:\n",
    "        sense = sense + (t.decode().replace('\\n','').replace('\\r','').casefold().split(' '))    \n",
    "\n",
    "sense2 = remove_punct(sense)\n",
    "sense3 = [w for w in sense2 if w]\n",
    "sense4 = remove_stops(sense3)\n",
    "sense5 = find_top25_words(sense4)\n",
    "print (sense5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "mrs/miss\n",
    "very\n",
    "more\n",
    "such\n",
    "much\n",
    "herself\n",
    "time\n",
    "now\n",
    "know\n",
    "sister\n",
    "though\n",
    "well\n",
    "think\n",
    "mother\n",
    "before\n",
    "never\n",
    "thing\n",
    "nothing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 109,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[('mr', 815), ('elizabeth', 610), ('very', 487), ('darcy', 401), ('such', 389), ('mrs', 358), ('much', 328), ('more', 323), ('bennet', 308), ('one', 297), ('miss', 294), ('jane', 278), ('bingley', 272), ('know', 237), ('before', 229), ('herself', 227), ('though', 226), ('never', 221), ('well', 219), ('soon', 217), ('think', 211), ('now', 211), ('time', 203), ('good', 196), ('lady', 194)]\n"
     ]
    }
   ],
   "source": [
    "##Austen - Pride & Predujice\n",
    "from urllib.request import urlopen\n",
    "import string\n",
    "with urlopen('http://www.textfiles.com/etext/FICTION/austen-pride-757.txt') as src:\n",
    "    pride = []\n",
    "    txt = src.readlines()\n",
    "    for t in txt:\n",
    "        pride = pride + (t.decode().replace('\\n','').replace('\\r','').casefold().split(' '))    \n",
    "\n",
    "pride2 = remove_punct(pride)\n",
    "pride3 = [w for w in pride2 if w]\n",
    "pride4 = remove_stops(pride3)\n",
    "pride5 = find_top25_words(pride4)\n",
    "print (pride5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "mr\n",
    "very\n",
    "such\n",
    "mrs/miss\n",
    "much\n",
    "more\n",
    "know\n",
    "before\n",
    "herself\n",
    "though\n",
    "never\n",
    "well\n",
    "soon\n",
    "think\n",
    "now\n",
    "time\n",
    "good\n",
    "lady"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 110,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[('very', 1187), ('mr', 1124), ('emma', 751), ('mrs', 687), ('miss', 587), ('much', 474), ('such', 471), ('more', 463), ('one', 428), ('harriet', 391), ('thing', 385), ('think', 384), ('weston', 382), ('little', 361), ('being', 358), ('well', 353), ('never', 346), ('knightley', 337), ('know', 322), ('elton', 317), ('good', 307), ('now', 302), ('quite', 275), ('jane', 272), ('herself', 267)]\n"
     ]
    }
   ],
   "source": [
    "##Austen - Emma\n",
    "from urllib.request import urlopen\n",
    "import string\n",
    "with urlopen('http://www.textfiles.com/etext/FICTION/austen-emma-754.txt') as src:\n",
    "    emma = []\n",
    "    txt = src.readlines()\n",
    "    for t in txt:\n",
    "        emma = emma + (t.decode().replace('\\n','').replace('\\r','').casefold().split(' '))    \n",
    "\n",
    "emma2 = remove_punct(emma)\n",
    "emma3 = [w for w in emma2 if w]\n",
    "emma4 = remove_stops(emma3)\n",
    "emma5 = find_top25_words(emma4)\n",
    "print (emma5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "very\n",
    "mr\n",
    "mrs/miss\n",
    "much\n",
    "such\n",
    "more\n",
    "thing\n",
    "think\n",
    "little\n",
    "being\n",
    "well\n",
    "never\n",
    "know\n",
    "good\n",
    "now\n",
    "quite\n",
    "herself\n",
    "\n",
    "\n",
    "and now lets compare to other women writers around the same time"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 111,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[('jo', 1254), ('one', 866), ('little', 728), ('up', 647), ('meg', 638), ('amy', 573), ('laurie', 552), ('dont', 551), ('very', 494), ('out', 482), ('beth', 418), ('good', 407), ('now', 399), ('go', 393), ('im', 390), ('well', 376), ('never', 375), ('much', 371), ('old', 366), ('see', 361), ('over', 353), ('more', 346), ('away', 331), ('mother', 329), ('time', 321)]\n"
     ]
    }
   ],
   "source": [
    "## Louisa May Alcott - Little Women\n",
    "from urllib.request import urlopen\n",
    "import string\n",
    "with urlopen('http://www.textfiles.com/etext/FICTION/li_women') as src:\n",
    "    little = []\n",
    "    txt = src.readlines()\n",
    "    for t in txt:\n",
    "        little = little + (t.decode().replace('\\n','').replace('\\r','').casefold().split(' '))    \n",
    "\n",
    "little2 = remove_punct(little)\n",
    "little3 = [w for w in little2 if w]\n",
    "little4 = remove_stops(little3)\n",
    "little5 = find_top25_words(little4)\n",
    "print (little5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "little\n",
    "up\n",
    "dont\n",
    "very\n",
    "out\n",
    "good\n",
    "now\n",
    "go\n",
    "im\n",
    "well\n",
    "never\n",
    "much\n",
    "old\n",
    "see\n",
    "over\n",
    "more\n",
    "away\n",
    "mother\n",
    "time"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 112,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[('now', 666), ('one', 579), ('mr', 542), ('out', 402), ('up', 384), ('very', 377), ('more', 362), ('little', 342), ('jane', 339), ('well', 325), ('rochester', 317), ('sir', 314), ('miss', 308), ('never', 294), ('before', 286), ('see', 276), ('such', 257), ('thought', 256), ('over', 255), ('mrs', 250), ('go', 248), ('down', 245), ('again', 245), ('still', 245), ('shall', 241)]\n"
     ]
    }
   ],
   "source": [
    "##Bronte - Jane Eyre\n",
    "from urllib.request import urlopen\n",
    "import string\n",
    "with urlopen('http://www.textfiles.com/etext/FICTION/bronte-jane-178.txt') as src:\n",
    "    jane = []\n",
    "    txt = src.readlines()\n",
    "    for t in txt:\n",
    "        jane = jane + (t.decode().replace('\\n','').replace('\\r','').casefold().split(' '))    \n",
    "\n",
    "jane2 = remove_punct(jane)\n",
    "jane3 = [w for w in jane2 if w]\n",
    "jane4 = remove_stops(jane3)\n",
    "jane5 = find_top25_words(jane4)\n",
    "print (jane5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "now\n",
    "mr\n",
    "out\n",
    "up\n",
    "very\n",
    "more\n",
    "little\n",
    "well\n",
    "sir\n",
    "miss/mrs\n",
    "never\n",
    "before\n",
    "see\n",
    "such\n",
    "thought\n",
    "over\n",
    "go\n",
    "down\n",
    "again\n",
    "still\n",
    "shall\n",
    "\n",
    "and compared to a book about a women written in the same time period by a man"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 113,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[('levin', 1524), ('up', 1287), ('one', 1201), ('out', 1004), ('now', 896), ('vronsky', 779), ('more', 747), ('anna', 742), ('well', 696), ('come', 682), ('go', 678), ('very', 673), ('know', 669), ('went', 638), ('alexei', 625), ('himself', 615), ('see', 613), ('kitty', 600), ('over', 581), ('time', 554), ('thought', 552), ('felt', 551), ('stepan', 550), ('eyes', 546), ('yes', 544)]\n"
     ]
    }
   ],
   "source": [
    "##Tolstoy - Anna Karenina\n",
    "from urllib.request import urlopen\n",
    "import string\n",
    "with urlopen('http://www.textfiles.com/etext/FICTION/anna_karenina') as src:\n",
    "    relig = []\n",
    "    txt = src.readlines()\n",
    "    for t in txt:\n",
    "        relig = relig + (t.decode().replace('\\n','').replace('\\r','').casefold().split(' '))    \n",
    "\n",
    "relig2 = remove_punct(relig)\n",
    "relig3 = [w for w in relig2 if w]\n",
    "relig4 = remove_stops(relig3)\n",
    "relig5 = find_top25_words(relig4)\n",
    "print (relig5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "up\n",
    "out\n",
    "now\n",
    "more\n",
    "well\n",
    "come\n",
    "go\n",
    "very\n",
    "know\n",
    "went\n",
    "himself\n",
    "see\n",
    "over\n",
    "time\n",
    "thought\n",
    "felt\n",
    "eyes\n",
    "yes\n",
    "\n",
    "Lets try something else; see if we can categorize religious documents."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 95,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[('shall', 9838), ('unto', 8997), ('lord', 7830), ('thou', 5474), ('thy', 4600), ('god', 4442), ('ye', 3982), ('thee', 3826), ('out', 2775), ('upon', 2748), ('man', 2613), ('israel', 2565), ('up', 2380), ('son', 2370), ('hath', 2264), ('king', 2258), ('people', 2139), ('came', 2093), ('house', 2024), ('come', 1971), ('one', 1967), ('children', 1802), ('before', 1796), ('day', 1734), ('land', 1718)]\n"
     ]
    }
   ],
   "source": [
    "##The bible\n",
    "from urllib.request import urlopen\n",
    "import string\n",
    "with urlopen('http://www.textfiles.com/etext/FICTION/bible10.txt') as src:\n",
    "    relig = []\n",
    "    txt = src.readlines()\n",
    "    for t in txt:\n",
    "        relig = relig + (t.decode().replace('\\n','').replace('\\r','').casefold().split(' '))    \n",
    "\n",
    "relig2 = remove_punct(relig)\n",
    "relig3 = [w for w in relig2 if w]\n",
    "relig4 = remove_stops(relig3)\n",
    "relig5 = find_top25_words(relig4)\n",
    "print (relig5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "Again, a lot of fluff. If we keep only nouns & verbs we're left with:\n",
    "    lord\n",
    "    god\n",
    "    came/come\n",
    "    man\n",
    "    isreal\n",
    "    son\n",
    "    king\n",
    "    people\n",
    "    house\n",
    "    children\n",
    "    day\n",
    "    land"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 96,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[('thou', 1087), ('thee', 921), ('thy', 898), ('things', 551), ('god', 507), ('unto', 354), ('one', 348), ('those', 313), ('lord', 306), ('o', 301), ('out', 285), ('more', 280), ('good', 279), ('now', 279), ('made', 267), ('man', 249), ('earth', 243), ('time', 227), ('upon', 223), ('being', 219), ('soul', 210), ('such', 208), ('through', 201), ('heaven', 198), ('life', 198)]\n"
     ]
    }
   ],
   "source": [
    "##St. Augustine writings\n",
    "from urllib.request import urlopen\n",
    "import string\n",
    "with urlopen('http://www.gutenberg.org/cache/epub/3296/pg3296.txt') as src:\n",
    "    aug = []\n",
    "    txt = src.readlines()\n",
    "    for t in txt[37:9369]:\n",
    "        aug = aug + (t.decode().replace('\\n','').replace('\\r','').casefold().split(' '))    \n",
    "\n",
    "aug2 = remove_punct(aug)\n",
    "aug3 = [w for w in aug2 if w]\n",
    "aug4 = remove_stops(aug3)\n",
    "aug5 = find_top25_words(aug4)\n",
    "print (aug5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "Keeping only nouns gives:\n",
    "        things\n",
    "        god\n",
    "        lord\n",
    "        more\n",
    "        good\n",
    "        now\n",
    "        made\n",
    "        man\n",
    "        earth\n",
    "        time\n",
    "        being\n",
    "        soul\n",
    "        heaven\n",
    "        life\n",
    "So we have lord and god in common but both of these words were found in the shakespearean text and the marlowe, \n",
    "although not both together...\n",
    "\n",
    "Lets try another one, not christian."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 97,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[('god', 788), ('abraham', 551), ('thou', 503), ('upon', 367), ('thy', 285), ('one', 278), ('earth', 271), ('unto', 271), ('adam', 252), ('man', 239), ('before', 234), ('thee', 234), ('lord', 225), ('world', 213), ('day', 206), ('angels', 206), ('son', 189), ('men', 185), ('time', 183), ('first', 169), ('shall', 168), ('himself', 161), ('out', 161), ('made', 158), ('king', 154)]\n"
     ]
    }
   ],
   "source": [
    "##Legends of the Jews volume 1\n",
    "from urllib.request import urlopen\n",
    "import string\n",
    "with urlopen('http://www.gutenberg.org/cache/epub/1493/pg1493.txt') as src:\n",
    "    leg = []\n",
    "    txt = src.readlines()\n",
    "    for t in txt[37:9369]:\n",
    "        leg = leg + (t.decode().replace('\\n','').replace('\\r','').casefold().split(' '))    \n",
    "\n",
    "leg2 = remove_punct(leg)\n",
    "leg3 = [w for w in leg2 if w]\n",
    "leg4 = remove_stops(leg3)\n",
    "leg5 = find_top25_words(leg4)\n",
    "print (leg5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "nouns:\n",
    "    god\n",
    "    abraham\n",
    "    earth\n",
    "    adam\n",
    "    man\n",
    "    lord\n",
    "    world\n",
    "    day\n",
    "    angels\n",
    "    son\n",
    "    men\n",
    "    time\n",
    "    himself\n",
    "    made\n",
    "    king\n",
    "now, we have 3 western religious documents that have 4-5 words in common:\n",
    "    lord, god, man, (earth aug&leg)\n",
    "lets see if these flow over to other religions. islam should be similar so that's first"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 98,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[('god', 2870), ('shall', 1725), ('ye', 1517), ('hath', 779), ('those', 721), ('lord', 667), ('thou', 612), ('thee', 485), ('believe', 398), ('o', 386), ('verily', 377), ('one', 355), ('day', 333), ('people', 331), ('earth', 330), ('thy', 326), ('see', 322), ('men', 319), ('down', 316), ('come', 312), ('sent', 294), ('signs', 264), ('fear', 261), ('upon', 246), ('before', 239)]\n"
     ]
    }
   ],
   "source": [
    "##Islam - The Koran\n",
    "from urllib.request import urlopen\n",
    "import string\n",
    "with urlopen('http://www.gutenberg.org/cache/epub/2800/pg2800.txt') as src:\n",
    "    islam= []\n",
    "    txt = src.readlines()\n",
    "    for t in txt[8876:39809]:\n",
    "        islam = islam + (t.decode().replace('\\n','').replace('\\r','').casefold().split(' '))    \n",
    "\n",
    "islam2 = remove_punct(islam)\n",
    "islam3 = [w for w in islam2 if w]\n",
    "islam4 = remove_stops(islam3)\n",
    "islam5 = find_top25_words(islam4)\n",
    "print (islam5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "nouns:\n",
    "    god\n",
    "    lord\n",
    "    believe\n",
    "    day\n",
    "    people\n",
    "    earth\n",
    "    see\n",
    "    men\n",
    "    come\n",
    "    sent\n",
    "    signs\n",
    "    fear\n",
    "again the same words are present (lord, god, men (form of man), and earth)    \n",
    "now lets see if it carries to any of the eastern religions. \n",
    "Hinduism first:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 99,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[('o', 2320), ('thou', 1624), ('king', 1179), ('son', 955), ('great', 941), ('one', 833), ('thy', 825), ('thee', 814), ('unto', 795), ('those', 710), ('shall', 625), ('having', 545), ('continued', 538), ('hath', 531), ('thus', 460), ('upon', 419), ('sons', 418), ('became', 412), ('men', 391), ('therefore', 388), ('brahmana', 380), ('monarch', 378), ('art', 374), ('parva', 362), ('race', 362)]\n"
     ]
    }
   ],
   "source": [
    "##Hindu - The Mahabharata of Krishna-Dwaipayana Vyasa\n",
    "from urllib.request import urlopen\n",
    "import string\n",
    "with urlopen('http://www.gutenberg.org/cache/epub/7864/pg7864.txt') as src:\n",
    "    hindu = []\n",
    "    txt = src.readlines()\n",
    "    for t in txt[237:21594]:\n",
    "        hindu = hindu + (t.decode().replace('\\n','').replace('\\r','').casefold().split(' '))    \n",
    "\n",
    "hindu2 = remove_punct(hindu)\n",
    "hindu3 = [w for w in hindu2 if w]\n",
    "hindu4 = remove_stops(hindu3)\n",
    "hindu5 = find_top25_words(hindu4)\n",
    "print (hindu5)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "    king\n",
    "    son\n",
    "    great\n",
    "    having\n",
    "    continues\n",
    "    became\n",
    "    men\n",
    "    monarch\n",
    "    art\n",
    "    race"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 101,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[('one', 741), ('blessed', 525), ('truth', 305), ('thou', 298), ('buddha', 239), ('o', 192), ('man', 190), ('life', 183), ('thy', 175), ('world', 153), ('good', 144), ('tathagata', 144), ('lord', 142), ('king', 142), ('mind', 141), ('self', 138), ('now', 137), ('great', 131), ('ananda', 125), ('heart', 116), ('evil', 116), ('having', 114), ('thee', 114), ('bhikkhus', 105), ('those', 101)]\n"
     ]
    }
   ],
   "source": [
    "##Buddhist - Buddha, The Gospel\n",
    "from urllib.request import urlopen\n",
    "import string\n",
    "with urlopen('http://www.textfiles.com/etext/NONFICTION/gospel') as src:\n",
    "    budd = []\n",
    "    txt = src.readlines()\n",
    "    for t in txt:\n",
    "        budd = budd + (t.decode().replace('\\n','').replace('\\r','').casefold().split(' '))    \n",
    "\n",
    "budd2 = remove_punct(budd)\n",
    "budd3 = [w for w in budd2 if w]\n",
    "budd4 = remove_stops(budd3)\n",
    "budd5 = find_top25_words(budd4)\n",
    "print (budd5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "    blessed\n",
    "    truth\n",
    "    man\n",
    "    life\n",
    "    world\n",
    "    good\n",
    "    lord\n",
    "    king\n",
    "    mind\n",
    "    self\n",
    "    heart\n",
    "    evil\n",
    "    having"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 102,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[('one', 379), ('more', 248), ('man', 219), ('even', 187), ('such', 151), ('itself', 145), ('perhaps', 144), ('himself', 132), ('men', 121), ('good', 119), ('still', 115), ('something', 109), ('new', 98), ('always', 96), ('themselves', 90), ('german', 89), ('out', 89), ('much', 82), ('time', 81), ('soul', 80), ('great', 79), ('love', 77), ('very', 75), ('morality', 75), ('woman', 74)]\n"
     ]
    }
   ],
   "source": [
    "##Atheism: Beyond Good and Evil, by Friedrich Nietzsche\n",
    "from urllib.request import urlopen\n",
    "import string\n",
    "with urlopen('http://www.gutenberg.org/cache/epub/4363/pg4363.txt') as src:\n",
    "    ath = []\n",
    "    txt = src.readlines()\n",
    "    for t in txt[148:6138]:\n",
    "        ath = ath + (t.decode().replace('\\n','').replace('\\r','').casefold().split(' '))    \n",
    "\n",
    "ath2 = remove_punct(ath)\n",
    "ath3 = [w for w in ath2 if w]\n",
    "ath4 = remove_stops(ath3)\n",
    "ath5 = find_top25_words(ath4)\n",
    "print (ath5)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "    man/men\n",
    "    itself\n",
    "    himself/themselves\n",
    "    good\n",
    "    something\n",
    "    time\n",
    "    soul\n",
    "    love\n",
    "    morality\n",
    "    woman"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "Medical Texts"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 103,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[('plate', 754), ('artery', 643), ('muscle', 476), ('vessels', 463), ('part', 378), ('internal', 347), ('side', 328), ('b', 310), ('external', 306), ('between', 294), ('c', 288), ('fascia', 283), ('d', 279), ('two', 272), ('hernia', 267), ('canal', 255), ('left', 234), ('f', 223), ('right', 222), ('fig', 221)]\n"
     ]
    }
   ],
   "source": [
    "##Surgical Anatomy BY JOSEPH MACLISE\n",
    "from urllib.request import urlopen\n",
    "import string\n",
    "with urlopen('http://www.gutenberg.org/cache/epub/24440/pg24440.txt') as src:\n",
    "    medi = []\n",
    "    txt = src.readlines()\n",
    "    for t in txt[1207:13394]:\n",
    "        medi = medi + (t.decode().replace('\\n','').replace('\\r','').casefold().split(' '))    \n",
    "\n",
    "medi2 = remove_punct(medi)\n",
    "medi3 = [w for w in medi2 if w]\n",
    "medi4 = remove_stops(medi3)\n",
    "medi5 = find_top20_words(medi4)\n",
    "print (medi5)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "plate\n",
    "artery\n",
    "muscle\n",
    "vessels\n",
    "part\n",
    "internal\n",
    "side\n",
    "external\n",
    "between\n",
    "fascia\n",
    "hernia\n",
    "canal\n",
    "left\n",
    "right"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 104,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[('medical', 62), ('dr', 59), ('one', 56), ('case', 41), ('more', 41), ('upon', 37), ('time', 36), ('physician', 34), ('physicians', 29), ('cases', 29), ('made', 29), ('two', 28), ('being', 26), ('medicine', 25), ('found', 25), ('first', 23), ('well', 23), ('very', 22), ('health', 22), ('patient', 22)]\n"
     ]
    }
   ],
   "source": [
    "##Medical Papers - The Cleveland Medical Gazette, Vol. I. No. 3., January 1886\n",
    "from urllib.request import urlopen\n",
    "import string\n",
    "with urlopen('https://www.gutenberg.org/files/52874/52874-0.txt') as src:\n",
    "    medjo = []\n",
    "    txt = src.readlines()\n",
    "    for t in txt[43:1921]:\n",
    "        medjo = medjo + (t.decode().replace('\\n','').replace('\\r','').casefold().split(' '))    \n",
    "\n",
    "medjo2 = remove_punct(medjo)\n",
    "medjo3 = [w for w in medjo2 if w]\n",
    "medjo4 = remove_stops(medjo3)\n",
    "medjo5 = find_top20_words(medjo4)\n",
    "print (medjo5)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "medical\n",
    "dr\n",
    "case\n",
    "time\n",
    "physician\n",
    "made\n",
    "being\n",
    "medicine\n",
    "found\n",
    "well\n",
    "health\n",
    "patient"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 105,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[('nursing', 767), ('nurse', 282), ('human', 231), ('being', 212), ('nurses', 183), ('man', 167), ('patient', 164), ('world', 161), ('experience', 158), ('one', 154), ('situation', 132), ('humanistic', 132), ('through', 130), ('more', 125), ('patients', 125), ('each', 122), ('lived', 109), ('clinical', 108), ('time', 104), ('dialogue', 101)]\n"
     ]
    }
   ],
   "source": [
    "##Medical Papers - Humanistic Nursing\n",
    "from urllib.request import urlopen\n",
    "import string\n",
    "with urlopen('http://www.gutenberg.org/cache/epub/25020/pg25020.txt') as src:\n",
    "    nurse = []\n",
    "    txt = src.readlines()\n",
    "    for t in txt[242:6094]:\n",
    "        nurse = nurse + (t.decode().replace('\\n','').replace('\\r','').casefold().split(' '))    \n",
    "\n",
    "nurse2 = remove_punct(nurse)\n",
    "nurse3 = [w for w in nurse2 if w]\n",
    "nurse4 = remove_stops(nurse3)\n",
    "nurse5 = find_top20_words(nurse4)\n",
    "print (nurse5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "nursing\n",
    "human\n",
    "being\n",
    "man\n",
    "patient\n",
    "world\n",
    "experience\n",
    "situation\n",
    "humanistic\n",
    "patients\n",
    "lived\n",
    "clinical\n",
    "time\n",
    "dialogue"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 107,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[]\n"
     ]
    }
   ],
   "source": [
    "##Medical Papers - Humanistic Nursing\n",
    "from urllib.request import urlopen\n",
    "import string\n",
    "locale = urlopen('http://apps.who.int/medicinedocs/documents/s17078e/s17078e.pdf')\n",
    "diag_file = open(\"document.pdf\", 'w')\n",
    "diag = diag_file.write(locale.read())\n",
    "diag_file.close\n",
    "\n",
    "txt = src.readlines()\n",
    "    for t in txt[242:6094]:\n",
    "        nurse = nurse + (t.decode().replace('\\n','').replace('\\r','').casefold().split(' '))    \n",
    "\n",
    "nurse2 = remove_punct(nurse)\n",
    "nurse3 = [w for w in nurse2 if w]\n",
    "nurse4 = remove_stops(nurse3)\n",
    "nurse5 = find_top20_words(nurse4)\n",
    "print (nurse5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.4.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
